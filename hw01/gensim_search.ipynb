{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d96398f",
   "metadata": {},
   "source": [
    "## RRDV con Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec4795",
   "metadata": {},
   "source": [
    "Importamos librerías de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee6b98ad32c1eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T01:11:36.264188Z",
     "start_time": "2024-08-28T01:11:36.261221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora, similarities\n",
    "\n",
    "from documents import load_docs, Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37945334",
   "metadata": {},
   "source": [
    "Cargamos nuestros documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614ae8f711af8f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T01:11:38.513754Z",
     "start_time": "2024-08-28T01:11:36.310226Z"
    }
   },
   "outputs": [],
   "source": [
    "all_docs = load_docs(Path(\"./data/docs-raw-texts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cc892",
   "metadata": {},
   "source": [
    "Vamos a sintetizar todo en una clase llamada `GensimSearch`. Su similitud con la que construimos manualmente para RRDV es evidente, solo que el cálculo del TF-IDF y las similitudes son mucho más directas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff73a770f556d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T01:11:38.531784Z",
     "start_time": "2024-08-28T01:11:38.526685Z"
    }
   },
   "outputs": [],
   "source": [
    "class GensimSearch:\n",
    "    def __init__(self, docs: List[Document]):\n",
    "        \"\"\"\n",
    "        Inicializa el RRDV con funciones de Gensim con una lista de documentos.\n",
    "\n",
    "        Args:\n",
    "            docs (List[Document]): Lista de objetos Document para construir el índice TF-IDF.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "\n",
    "        # Implemente el concepto de un Dictionary, es decir, mapear palabras a enteros.\n",
    "        self.dictionary = corpora.Dictionary(all_docs)\n",
    "\n",
    "        # El corpus se construirá con el método doc2bow de gensim, que cuenta las ocurrencias de cada término en cada documento.\n",
    "        self.corpus = [self.dictionary.doc2bow(doc) for doc in all_docs]\n",
    "\n",
    "        # Construimos el modelo TF-IDF de Gensim con nuestro corpus.\n",
    "        self.model = TfidfModel(self.corpus)\n",
    "\n",
    "        # Calcula la similitud coseno para nuestro corpus y el modelo TF-IDF.\n",
    "        self.index = similarities.MatrixSimilarity(self.model[self.corpus])\n",
    "        \n",
    "    def search(self, query_document: Document, min_similarity: float = 0.0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Realiza una búsqueda para encontrar documentos similares al documento de consulta.\n",
    "\n",
    "        Args:\n",
    "            query_document (Document): Documento de consulta para buscar similitudes.\n",
    "            min_similarity (float): Umbral mínimo de similitud para filtrar resultados. Por defecto es 0.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame con documentos relevantes y sus similitudes.\n",
    "        \"\"\"\n",
    "        # Tenemos que aplicar el mismo procesamiento a la consulta, es decir, conteo de términos (doc2bow), aplicarle el modelo TF-IDF, y calcular similitud coseno con el índice ya construido.\n",
    "        query_bow = self.dictionary.doc2bow(query_document)\n",
    "        query_tfidf = self.model[query_bow]\n",
    "        sims = self.index[query_tfidf]\n",
    "\n",
    "        # Crear un DataFrame con los resultados de similitud\n",
    "        results = pd.DataFrame({\n",
    "            'similarity': sims,\n",
    "            'doc': self.docs\n",
    "        }, index=[doc.name for doc in self.docs])\n",
    "        \n",
    "        # Ordenar los resultados por similitud de mayor a menor\n",
    "        results.sort_values(by='similarity', ascending=False, inplace=True)\n",
    "\n",
    "        # Filtrar los resultados por similitud mínima\n",
    "        results = results[results['similarity'] > min_similarity]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_search(self, queries: List[Document], output_path: Path):\n",
    "        \"\"\"\n",
    "        Evalúa las consultas y escribe los resultados en un archivo de salida.\n",
    "    \n",
    "        Args:\n",
    "            queries (List[Document]): Lista de documentos de consulta para evaluar.\n",
    "            output_path (Path): Ruta del archivo donde se guardarán los resultados.\n",
    "        \"\"\"\n",
    "        with open(output_path, 'w') as output_file:\n",
    "            for query in queries:\n",
    "                relevant_docs = self.search(query_document=query)    \n",
    "                result_texts = [f'{doc_name}:{row.similarity}' for doc_name, row in relevant_docs.iterrows()]\n",
    "                output_file.write(f\"{query.name}\\t{','.join(result_texts)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf68c5",
   "metadata": {},
   "source": [
    "Construimos nuestra clase con nuestros documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T01:11:38.887931Z",
     "start_time": "2024-08-28T01:11:38.590233Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_search = GensimSearch(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792dee5d",
   "metadata": {},
   "source": [
    "Y calculamos todos los queries, almacenándolos en el formato especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2b9d4456cdbd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T01:11:39.078665Z",
     "start_time": "2024-08-28T01:11:38.896597Z"
    }
   },
   "outputs": [],
   "source": [
    "all_queries = load_docs(Path(\"./data/queries-raw-texts\"))\n",
    "gensim_search.evaluate_search(all_queries, output_path='./data/GESIM-consultas_resultados')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
