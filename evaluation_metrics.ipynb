{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de métricas de evaluación de IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Se define como la proporción de documentos recuperados (RET) que son relevantes (REL).\n",
    "\n",
    "$\\mathcal{P} = \\frac{|\\text{RET} \\: \\cap \\: \\text{REL}|}{|\\text{RET}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(relevance_query: List[int]):\n",
    "\n",
    "    assert set(relevance_query).issubset((0,1)), \"Only binary values (0, 1) allowed.\"\n",
    "    \n",
    "    return sum(relevance_query) / len(relevance_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision at K\n",
    "\n",
    "Se define como la proporción de documentos top-K recuperados que son relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevance_query: List[int], k: int):\n",
    "\n",
    "    assert set(relevance_query).issubset((0,1)), \"Only binary values (0, 1) allowed.\"\n",
    "    assert k > 0, \"K must be greater or equal than 1.\"\n",
    "\n",
    "    return sum(relevance_query[:k]) / len(relevance_query[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k([0, 0, 0, 1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall at K\n",
    "\n",
    "Se define como la proporción de documentos relevantes que se recuperan en el top K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(relevance_query: List[int], k: int, num_relevant_docs: int):\n",
    "\n",
    "    assert set(relevance_query).issubset((0,1)), \"Only binary values (0, 1) allowed.\"\n",
    "    assert k > 0, \"K must be greater or equal than 1.\"\n",
    "    assert num_relevant_docs > 0, \"Number of relevant docs must be greater or equal than 1.\"\n",
    "\n",
    "    return sum(relevance_query[:k]) / num_relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k([0, 0, 0, 1], 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average precision\n",
    "\n",
    "Se define como el promedio de los **Precision at K**, calculados de manera iterativa al aumentar iterativamente **K** cada vez que se encuentra un documento relevante. El cálculo se detiene cuando se obtiene un **recall** de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(relevance_query: List[int]):\n",
    "\n",
    "    assert set(relevance_query).issubset((0,1)), \"Only binary values (0, 1) allowed.\"\n",
    "    \n",
    "    cumulative_precision = 0\n",
    "    relevant_count = 0\n",
    "\n",
    "    for observation_count, relevance in enumerate(relevance_query, 1):\n",
    "        if relevance:\n",
    "            relevant_count += 1\n",
    "            cumulative_precision += relevant_count / observation_count\n",
    "\n",
    "    return cumulative_precision / relevant_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5961904761904762"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision([0, 1, 0, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision (MAP)\n",
    "\n",
    "Promedio de calcular el **Average Precision** para varias consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(relevance_queries: List[List[int]]):\n",
    "\n",
    "    assert all(set(sublist).issubset((0, 1)) for sublist in relevance_queries), \"Only binary values (0, 1) allowed in all query results.\"\n",
    "    \n",
    "    return sum(average_precision(relevance_query) for relevance_query in relevance_queries) / len(relevance_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision([[1, 0, 1], [0, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discounted Cumulative Gain at K\n",
    "\n",
    "Sea $\\text{REL}_i$ la relevancia asociada con el documento en el rango $i$, $1 \\leq i \\leq K$. Definimos:\n",
    "\n",
    "$\\text{DGG@K} = \\sum_{i = 1}^{K} \\frac{\\text{REL}_i}{\\log_2 (\\max (i,\\: 2))}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_cumulative_gain(relevance_query: List[int], k: int):\n",
    "    \n",
    "    assert all(x >= 0 for x in relevance_query), \"All elements must be integers greater than or equal to 0.\"\n",
    "    assert k > 0, \"K must be greater or equal than 1.\"\n",
    "\n",
    "    return sum(relevance / np.log2(max(i, 2)) for i, relevance in enumerate(relevance_query[:k], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.279642067948915"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_cumulative_gain([4, 4, 3, 0, 0, 1, 3, 3, 3, 0], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain at K\n",
    "\n",
    "Dada la DGG@K de una consulta, se divide entre el mejor DGG@K posible para esa consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_discounted_cumulative_gain(relevance_query: List[int], k: int):\n",
    "\n",
    "    assert all(x >= 0 for x in relevance_query), \"All elements must be integers greater than or equal to 0.\"\n",
    "    assert k > 0, \"K must be greater or equal than 1.\"\n",
    "\n",
    "    rq = relevance_query.copy()\n",
    "    rq.sort(reverse=True)\n",
    "    return discounted_cumulative_gain(relevance_query, k) / discounted_cumulative_gain(rq, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7424602308163405"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_discounted_cumulative_gain([4,4,3,0,0,1,3,3,3,0], 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
