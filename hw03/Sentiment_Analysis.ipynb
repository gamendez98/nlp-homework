{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T20:09:42.909323Z",
     "start_time": "2024-09-14T20:09:42.240123Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "class CustomFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # TODO: extract features\n",
    "        return X\n",
    "\n",
    "\n",
    "def representation_to_document(document_representation: str):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "        document_representation: \n",
    "\n",
    "    Returns:\n",
    "        document_text, document_label\n",
    "    '''\n",
    "    word_counts = [term_representation.split(':') for term_representation in document_representation.split(' ')]\n",
    "    _, label = word_counts[-1]\n",
    "    word_counts = word_counts[:-1]\n",
    "    words = []\n",
    "    for term, count in word_counts:\n",
    "        words.extend([term] * int(count))\n",
    "    return ' '.join(words), label\n",
    "\n",
    "\n",
    "def load_documents(file_path: Path):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "        file_path: \n",
    "\n",
    "    Returns:\n",
    "        (document_texts, document_labels)\n",
    "    '''\n",
    "    with open(file_path, \"r\") as f:\n",
    "        document_representations = f.readlines()\n",
    "    return list(zip(*(representation_to_document(representation) for representation in document_representations)))\n",
    "\n",
    "\n",
    "def load_domain(domain_path: Path):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "        domain_path: \n",
    "\n",
    "    Returns:\n",
    "        train_df, val_df\n",
    "    '''\n",
    "    positive_document_counts, positive_document_labels = load_documents(domain_path / \"positive.review\")\n",
    "    negative_documents_counts, negative_documents_labels = load_documents(domain_path / \"negative.review\")\n",
    "    unlabeled_documents_counts, unlabeled_documents_labels = load_documents(domain_path / \"unlabeled.review\")\n",
    "    return (\n",
    "        pd.DataFrame({\n",
    "            'sentiment': positive_document_labels + negative_documents_labels,\n",
    "            'document': positive_document_counts + negative_documents_counts\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            'sentiment': unlabeled_documents_labels,\n",
    "            'document': unlabeled_documents_counts\n",
    "        })\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:09:46.854924Z",
     "start_time": "2024-09-14T20:09:46.848911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    return {\n",
    "        \"Precision (Macro)\": precision_macro,\n",
    "        \"Recall (Macro)\": recall_macro,\n",
    "        \"F1 Score (Macro)\": f1_macro,\n",
    "        \"Precision (Micro)\": precision_micro,\n",
    "        \"Recall (Micro)\": recall_micro,\n",
    "        \"F1 Score (Micro)\": f1_micro,\n",
    "    }"
   ],
   "id": "ad9a9c0fb5672c70",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:09:48.518770Z",
     "start_time": "2024-09-14T20:09:48.516131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_fit_model(X_train, y_train, vectorizer, middleware, model):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('middleware', middleware),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline"
   ],
   "id": "43f6a61dca5174",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:09:50.094874Z",
     "start_time": "2024-09-14T20:09:50.091301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_over_dataset(train_df, val_df):\n",
    "    identity_transformer = FunctionTransformer(lambda x: x)\n",
    "    transform_sparce = FunctionTransformer(lambda X: np.asarray(X.todense()))\n",
    "    X_train = train_df['document']\n",
    "    y_train = train_df['sentiment']\n",
    "    X_val = val_df['document']\n",
    "    y_val = val_df['sentiment']\n",
    "    model_parameters = [\n",
    "        {'vectorizer': TfidfVectorizer(), 'middleware': identity_transformer, 'model': LogisticRegression()},\n",
    "        {'vectorizer': CountVectorizer(), 'middleware': identity_transformer, 'model': LogisticRegression()},\n",
    "        # {'vectorizer': CustomFeature(), 'middleware': identity_transformer, 'model': LogisticRegression()},\n",
    "        {'vectorizer': TfidfVectorizer(max_features=10000), 'middleware': transform_sparce, 'model': GaussianNB()},\n",
    "        {'vectorizer': CountVectorizer(max_features=10000), 'middleware': transform_sparce, 'model': GaussianNB()},\n",
    "        # {'vectorizer': CustomFeature(), 'middleware': transform_sparce, 'model': GaussianNB()},\n",
    "    ]\n",
    "    all_results = []\n",
    "    for model_parameter in model_parameters:\n",
    "        model_info = {\n",
    "            'vectorizer': type(model_parameter['vectorizer']).__name__,\n",
    "            'model': type(model_parameter['model']).__name__,\n",
    "        }\n",
    "        model = create_fit_model(X_train, y_train, **model_parameter)\n",
    "        results = evaluate_model(model, X_val, y_val)\n",
    "        model_info.update(results)\n",
    "        all_results.append(model_info)\n",
    "    return pd.DataFrame(all_results)"
   ],
   "id": "80dee0a465e328c3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:09:52.405308Z",
     "start_time": "2024-09-14T20:09:52.402331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_domains(domains_path: Path):\n",
    "    domain_folders = [folder for folder in domains_path.iterdir() if folder.is_dir()]\n",
    "    all_results = []\n",
    "    for domain_folder in domain_folders:\n",
    "        domain_name = domain_folder.name\n",
    "        train_df, val_df = load_domain(domain_folder)\n",
    "        results = evaluate_over_dataset(train_df, val_df)\n",
    "        results['domain'] = domain_name\n",
    "        results['domain_train_size'] = len(train_df)\n",
    "        results['domain_test_size'] = len(val_df)\n",
    "        all_results.append(results)\n",
    "    return pd.concat(all_results, ignore_index=True)"
   ],
   "id": "5f0737d8d0bf8c89",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate different configurations per domain",
   "id": "9007836f2022bc52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:10:32.288935Z",
     "start_time": "2024-09-14T20:09:54.958039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "domain_wise_evaluation = evaluate_domains(Path(\"../data/processed_acl\"))\n",
    "domain_wise_evaluation"
   ],
   "id": "1e5c6fc83f6d71ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         vectorizer               model  Precision (Macro)  Recall (Macro)  \\\n",
       "0   TfidfVectorizer  LogisticRegression           0.865075        0.864866   \n",
       "1   CountVectorizer  LogisticRegression           0.881803        0.881712   \n",
       "2   TfidfVectorizer          GaussianNB           0.781939        0.781560   \n",
       "3   CountVectorizer          GaussianNB           0.807755        0.807209   \n",
       "4   TfidfVectorizer  LogisticRegression           0.832714        0.832171   \n",
       "5   CountVectorizer  LogisticRegression           0.826614        0.826630   \n",
       "6   TfidfVectorizer          GaussianNB           0.726477        0.725492   \n",
       "7   CountVectorizer          GaussianNB           0.734613        0.732652   \n",
       "8   TfidfVectorizer  LogisticRegression           0.859076        0.858961   \n",
       "9   CountVectorizer  LogisticRegression           0.860079        0.859816   \n",
       "10  TfidfVectorizer          GaussianNB           0.753694        0.752538   \n",
       "11  CountVectorizer          GaussianNB           0.779318        0.778998   \n",
       "12  TfidfVectorizer  LogisticRegression           0.843019        0.842603   \n",
       "13  CountVectorizer  LogisticRegression           0.834911        0.834518   \n",
       "14  TfidfVectorizer          GaussianNB           0.722535        0.722376   \n",
       "15  CountVectorizer          GaussianNB           0.677226        0.663399   \n",
       "\n",
       "    F1 Score (Macro)  Precision (Micro)  Recall (Micro)  F1 Score (Micro)  \\\n",
       "0           0.864896           0.864929        0.864929          0.864929   \n",
       "1           0.881734           0.881749        0.881749          0.881749   \n",
       "2           0.781562           0.781665        0.781665          0.781665   \n",
       "3           0.807001           0.807065        0.807065          0.807065   \n",
       "4           0.831768           0.831803        0.831803          0.831803   \n",
       "5           0.826621           0.826652        0.826652          0.826652   \n",
       "6           0.724777           0.724972        0.724972          0.724972   \n",
       "7           0.732499           0.733259        0.733259          0.733259   \n",
       "8           0.858982           0.859004        0.859004          0.859004   \n",
       "9           0.859845           0.859884        0.859884          0.859884   \n",
       "10          0.752094           0.752332        0.752332          0.752332   \n",
       "11          0.778999           0.779088        0.779088          0.779088   \n",
       "12          0.842647           0.842722        0.842722          0.842722   \n",
       "13          0.834558           0.834635        0.834635          0.834635   \n",
       "14          0.722225           0.722253        0.722253          0.722253   \n",
       "15          0.655952           0.662298        0.662298          0.662298   \n",
       "\n",
       "         domain  domain_train_size  domain_test_size  \n",
       "0       kitchen               2000              5945  \n",
       "1       kitchen               2000              5945  \n",
       "2       kitchen               2000              5945  \n",
       "3       kitchen               2000              5945  \n",
       "4         books               2000              4465  \n",
       "5         books               2000              4465  \n",
       "6         books               2000              4465  \n",
       "7         books               2000              4465  \n",
       "8   electronics               2000              5681  \n",
       "9   electronics               2000              5681  \n",
       "10  electronics               2000              5681  \n",
       "11  electronics               2000              5681  \n",
       "12          dvd               2000              3586  \n",
       "13          dvd               2000              3586  \n",
       "14          dvd               2000              3586  \n",
       "15          dvd               2000              3586  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>Precision (Macro)</th>\n",
       "      <th>Recall (Macro)</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "      <th>Precision (Micro)</th>\n",
       "      <th>Recall (Micro)</th>\n",
       "      <th>F1 Score (Micro)</th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_train_size</th>\n",
       "      <th>domain_test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.865075</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.864896</td>\n",
       "      <td>0.864929</td>\n",
       "      <td>0.864929</td>\n",
       "      <td>0.864929</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.881803</td>\n",
       "      <td>0.881712</td>\n",
       "      <td>0.881734</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.781560</td>\n",
       "      <td>0.781562</td>\n",
       "      <td>0.781665</td>\n",
       "      <td>0.781665</td>\n",
       "      <td>0.781665</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.807755</td>\n",
       "      <td>0.807209</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>0.807065</td>\n",
       "      <td>0.807065</td>\n",
       "      <td>0.807065</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.832171</td>\n",
       "      <td>0.831768</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>books</td>\n",
       "      <td>2000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.826614</td>\n",
       "      <td>0.826630</td>\n",
       "      <td>0.826621</td>\n",
       "      <td>0.826652</td>\n",
       "      <td>0.826652</td>\n",
       "      <td>0.826652</td>\n",
       "      <td>books</td>\n",
       "      <td>2000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.726477</td>\n",
       "      <td>0.725492</td>\n",
       "      <td>0.724777</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>books</td>\n",
       "      <td>2000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.732652</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.733259</td>\n",
       "      <td>0.733259</td>\n",
       "      <td>0.733259</td>\n",
       "      <td>books</td>\n",
       "      <td>2000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>0.858961</td>\n",
       "      <td>0.858982</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>electronics</td>\n",
       "      <td>2000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.860079</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.859845</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>electronics</td>\n",
       "      <td>2000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.753694</td>\n",
       "      <td>0.752538</td>\n",
       "      <td>0.752094</td>\n",
       "      <td>0.752332</td>\n",
       "      <td>0.752332</td>\n",
       "      <td>0.752332</td>\n",
       "      <td>electronics</td>\n",
       "      <td>2000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.779318</td>\n",
       "      <td>0.778998</td>\n",
       "      <td>0.778999</td>\n",
       "      <td>0.779088</td>\n",
       "      <td>0.779088</td>\n",
       "      <td>0.779088</td>\n",
       "      <td>electronics</td>\n",
       "      <td>2000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.843019</td>\n",
       "      <td>0.842603</td>\n",
       "      <td>0.842647</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>dvd</td>\n",
       "      <td>2000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.834911</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.834558</td>\n",
       "      <td>0.834635</td>\n",
       "      <td>0.834635</td>\n",
       "      <td>0.834635</td>\n",
       "      <td>dvd</td>\n",
       "      <td>2000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.722535</td>\n",
       "      <td>0.722376</td>\n",
       "      <td>0.722225</td>\n",
       "      <td>0.722253</td>\n",
       "      <td>0.722253</td>\n",
       "      <td>0.722253</td>\n",
       "      <td>dvd</td>\n",
       "      <td>2000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.677226</td>\n",
       "      <td>0.663399</td>\n",
       "      <td>0.655952</td>\n",
       "      <td>0.662298</td>\n",
       "      <td>0.662298</td>\n",
       "      <td>0.662298</td>\n",
       "      <td>dvd</td>\n",
       "      <td>2000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:10:32.330001Z",
     "start_time": "2024-09-14T20:10:32.327119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_consolidated_data(domains_path: Path):\n",
    "    all_train_dfs = []\n",
    "    all_test_dfs = []\n",
    "    domain_folders = [folder for folder in domains_path.iterdir() if folder.is_dir()]\n",
    "    for domain_folder in domain_folders:\n",
    "        train_df, val_df = load_domain(domain_folder)\n",
    "        train_df['domain'] = domain_folder.name\n",
    "        val_df['domain'] = domain_folder.name\n",
    "        all_train_dfs.append(train_df)\n",
    "        all_test_dfs.append(val_df)\n",
    "    consolidated_train_df = pd.concat(all_train_dfs, ignore_index=True)\n",
    "    consolidated_test_df = pd.concat(all_test_dfs, ignore_index=True)\n",
    "    return consolidated_train_df, consolidated_test_df\n",
    "\n",
    "\n",
    "def evaluate_consolidated(domains_path: Path):\n",
    "    consolidated_train_df, consolidated_test_df = get_consolidated_data(domains_path)\n",
    "    return evaluate_over_dataset(consolidated_train_df, consolidated_test_df)"
   ],
   "id": "7c6caca0568f01ce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate using one model for the whole dataset",
   "id": "2362ebfa83188f2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:18:50.101409Z",
     "start_time": "2024-09-14T20:18:24.464807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "single_model_evaluation = evaluate_consolidated(Path(\"../data/processed_acl\"))\n",
    "single_model_evaluation"
   ],
   "id": "cf8d04aa3862ecbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        vectorizer               model  Precision (Macro)  Recall (Macro)  \\\n",
       "0  TfidfVectorizer  LogisticRegression           0.869648        0.869539   \n",
       "1  CountVectorizer  LogisticRegression           0.876404        0.876398   \n",
       "2  TfidfVectorizer          GaussianNB           0.805935        0.804835   \n",
       "3  CountVectorizer          GaussianNB           0.802116        0.800735   \n",
       "\n",
       "   F1 Score (Macro)  Precision (Micro)  Recall (Micro)  F1 Score (Micro)  \n",
       "0          0.869487           0.869492        0.869492          0.869492  \n",
       "1          0.876401           0.876404        0.876404          0.876404  \n",
       "2          0.804544           0.804696        0.804696          0.804696  \n",
       "3          0.800379           0.800579        0.800579          0.800579  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>Precision (Macro)</th>\n",
       "      <th>Recall (Macro)</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "      <th>Precision (Micro)</th>\n",
       "      <th>Recall (Micro)</th>\n",
       "      <th>F1 Score (Micro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.869648</td>\n",
       "      <td>0.869539</td>\n",
       "      <td>0.869487</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>0.869492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.876398</td>\n",
       "      <td>0.876401</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.876404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.805935</td>\n",
       "      <td>0.804835</td>\n",
       "      <td>0.804544</td>\n",
       "      <td>0.804696</td>\n",
       "      <td>0.804696</td>\n",
       "      <td>0.804696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.802116</td>\n",
       "      <td>0.800735</td>\n",
       "      <td>0.800379</td>\n",
       "      <td>0.800579</td>\n",
       "      <td>0.800579</td>\n",
       "      <td>0.800579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## See best configuration for each domain according to f1",
   "id": "97a89e3c2ef70a86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:11:01.865966Z",
     "start_time": "2024-09-14T20:11:01.853453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_results = domain_wise_evaluation.groupby('domain').apply(\n",
    "    lambda df: df.nlargest(1, 'F1 Score (Macro)')).reset_index(drop=True)\n",
    "grouped_results"
   ],
   "id": "43f53c7cc885cf9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2359/3598008287.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_results = domain_wise_evaluation.groupby('domain').apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        vectorizer               model  Precision (Macro)  Recall (Macro)  \\\n",
       "0  TfidfVectorizer  LogisticRegression           0.832714        0.832171   \n",
       "1  TfidfVectorizer  LogisticRegression           0.843019        0.842603   \n",
       "2  CountVectorizer  LogisticRegression           0.860079        0.859816   \n",
       "3  CountVectorizer  LogisticRegression           0.881803        0.881712   \n",
       "\n",
       "   F1 Score (Macro)  Precision (Micro)  Recall (Micro)  F1 Score (Micro)  \\\n",
       "0          0.831768           0.831803        0.831803          0.831803   \n",
       "1          0.842647           0.842722        0.842722          0.842722   \n",
       "2          0.859845           0.859884        0.859884          0.859884   \n",
       "3          0.881734           0.881749        0.881749          0.881749   \n",
       "\n",
       "        domain  domain_train_size  domain_test_size  \n",
       "0        books               2000              4465  \n",
       "1          dvd               2000              3586  \n",
       "2  electronics               2000              5681  \n",
       "3      kitchen               2000              5945  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>Precision (Macro)</th>\n",
       "      <th>Recall (Macro)</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "      <th>Precision (Micro)</th>\n",
       "      <th>Recall (Micro)</th>\n",
       "      <th>F1 Score (Micro)</th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_train_size</th>\n",
       "      <th>domain_test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.832171</td>\n",
       "      <td>0.831768</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>books</td>\n",
       "      <td>2000</td>\n",
       "      <td>4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.843019</td>\n",
       "      <td>0.842603</td>\n",
       "      <td>0.842647</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>0.842722</td>\n",
       "      <td>dvd</td>\n",
       "      <td>2000</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.860079</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.859845</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>electronics</td>\n",
       "      <td>2000</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.881803</td>\n",
       "      <td>0.881712</td>\n",
       "      <td>0.881734</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2000</td>\n",
       "      <td>5945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare using single model or gated model",
   "id": "9f3d93da38aeab45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:16:56.182479Z",
     "start_time": "2024-09-14T20:16:56.177651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GatedSentimentClassifier:\n",
    "    def __init__(self, domain_pipes: dict[str, Pipeline]):\n",
    "        self.domain_pipes = domain_pipes\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        for domain, pipe in self.domain_pipes.items():\n",
    "            domain_data = X[X['domain'] == domain]\n",
    "            domain_labels = y[X['domain'] == domain]\n",
    "\n",
    "            X_domain = domain_data['document']\n",
    "            y_domain = domain_labels\n",
    "            pipe.fit(X_domain, y_domain)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            domain = row['domain']\n",
    "            if domain not in self.domain_pipes:\n",
    "                raise ValueError(f\"Domain '{domain}' not found in domain_pipes\")\n",
    "\n",
    "            pipe = self.domain_pipes[domain]\n",
    "            X_row = row['document']\n",
    "\n",
    "            # Predict using the corresponding pipeline\n",
    "            prediction = pipe.predict([X_row])\n",
    "            predictions.append(prediction[0])\n",
    "        return predictions\n",
    "\n"
   ],
   "id": "a9ed14643b389231",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We choose the best models according to the f1 score per domain",
   "id": "9505d7eed907e7f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:17:09.031777Z",
     "start_time": "2024-09-14T20:16:57.766910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gated_model = GatedSentimentClassifier({\n",
    "    'books': Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'dvd': Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'electronics': Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'kitchen': Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "})\n",
    "\n",
    "consolidated_train, consolidated_test = get_consolidated_data(Path(\"../data/processed_acl\"))\n",
    "\n",
    "X_train = consolidated_train[['document', 'domain']]\n",
    "y_train = consolidated_train['sentiment']\n",
    "\n",
    "gated_model.fit(X_train, y_train)"
   ],
   "id": "633c153c86822fcb",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:17:15.866977Z",
     "start_time": "2024-09-14T20:17:10.754050Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model(gated_model, consolidated_test[['document', 'domain']], consolidated_test['sentiment'])",
   "id": "6efb3bef1872b990",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision (Macro)': np.float64(0.8569909796756637),\n",
       " 'Recall (Macro)': np.float64(0.8569979355165842),\n",
       " 'F1 Score (Macro)': np.float64(0.8569897739838795),\n",
       " 'Precision (Micro)': np.float64(0.8569903948772679),\n",
       " 'Recall (Micro)': np.float64(0.8569903948772679),\n",
       " 'F1 Score (Micro)': np.float64(0.8569903948772679)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4369d281bce94246"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We choose the best model according to the f1 for the consolidated data",
   "id": "ed1089f5718c0c9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T20:22:46.559625Z",
     "start_time": "2024-09-14T20:22:37.248589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "single_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "single_model.fit(consolidated_train['document'], consolidated_train['sentiment'])\n",
    "\n",
    "single_model_evaluation = evaluate_model(single_model, consolidated_test['document'], consolidated_test['sentiment'])\n",
    "single_model_evaluation"
   ],
   "id": "da2118528b702f43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision (Macro)': np.float64(0.8764043204898988),\n",
       " 'Recall (Macro)': np.float64(0.8763979118994643),\n",
       " 'F1 Score (Macro)': np.float64(0.8764005366893186),\n",
       " 'Precision (Micro)': np.float64(0.8764039233623012),\n",
       " 'Recall (Micro)': np.float64(0.8764039233623012),\n",
       " 'F1 Score (Micro)': np.float64(0.8764039233623012)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
