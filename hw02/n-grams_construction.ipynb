{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:03:57.727670Z",
     "start_time": "2024-09-09T01:03:56.627346Z"
    }
   },
   "source": [
    "import nltk, pickle\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca estaba generalizando las funciones ya existentes, pero calculan los gramas con base en todo el texto plano, y no por oración. Lo dejo comentado por si acaso, aunque hice otra que sí los calcula por oración. Creo que así tiene más sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_tokenizer(text):\n",
    "#     import re\n",
    "#     \"\"\"\n",
    "#     Tokeniza un texto personalizado (para los casos de <s>, </s> y <UNK>).\n",
    "\n",
    "#     Args:\n",
    "#     text: El texto a tokenizar.\n",
    "\n",
    "#     Returns:\n",
    "#     Una lista de tokens.\n",
    "#     \"\"\"\n",
    "#     tokens = re.findall(r\"<[^>]+>|[\\w']+|[.,!?;]\", text)\n",
    "#     return tokens\n",
    "\n",
    "# def calculate_ngram_probabilities(corpus: str, n: int) -> Dict[Tuple[str, ...], float]:\n",
    "#     \"\"\"\n",
    "#     Calcula las probabilidades de n-gramas con suavizado de Laplace.\n",
    "\n",
    "#     Args:\n",
    "#         corpus: Lista de palabras.\n",
    "#         n: Tamaño del n-grama (1 para unigrama, 2 para bigrama, etc.).\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Un diccionario con las probabilidades de n-gramas.\n",
    "#     \"\"\"    \n",
    "#     tokens = custom_tokenizer(corpus)\n",
    "#     # Unigrama\n",
    "#     if n == 1:\n",
    "#         unigrams = Counter(tokens)\n",
    "#         V = len(unigrams)  # Tamaño del vocabulario\n",
    "#         total_words_in_corpus = sum(unigrams.values())\n",
    "        \n",
    "#         # Suavizado de Laplace para unigramas\n",
    "#         probabilities = {\n",
    "#             (word,): (count + 1) / (total_words_in_corpus + V)\n",
    "#             for word, count in unigrams.items()\n",
    "#         }\n",
    "#         return probabilities\n",
    "\n",
    "#     # Para n-gramas donde n > 1\n",
    "#     ngrams_list = list(nltk.ngrams(tokens, n))\n",
    "#     ngrams = Counter(ngrams_list)\n",
    "\n",
    "#     # Para (n-1)-gramas (bigramas para trigramas)\n",
    "#     n_minus_1_grams_list = list(nltk.ngrams(tokens, n - 1))\n",
    "#     n_minus_1_grams_count = Counter(n_minus_1_grams_list)\n",
    "\n",
    "#     V = len(set(tokens))  # Tamaño del vocabulario\n",
    "\n",
    "#     # Suavizado de Laplace para n-gramas\n",
    "#     probabilities = {\n",
    "#         ngram: (count + 1) / (n_minus_1_grams_count[ngram[:-1]] + V)  # ngram[:-1] es el (n-1)-grama\n",
    "#         for ngram, count in ngrams.items()\n",
    "#     }\n",
    "\n",
    "#     return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:03:59.809492Z",
     "start_time": "2024-09-09T01:03:59.801495Z"
    }
   },
   "source": [
    "def read_and_tokenize(file_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo de texto, tokeniza las oraciones y retorna una lista de listas de tokens.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Ruta al archivo de texto.\n",
    "        \n",
    "    Returns:\n",
    "        Lista de listas de tokens (cada oración tokenizada).\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    sentences = text.strip().split('\\n')\n",
    "    tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "\n",
    "def build_ngram_counts(tokenized_sentences, n):\n",
    "    \"\"\"\n",
    "    Cuenta los n-gramas de las oraciones tokenizadas usando nltk\n",
    "    \n",
    "    Args:\n",
    "        tokenized_sentences: Lista de listas de tokens.\n",
    "        n: Tamaño del n-grama.\n",
    "        \n",
    "    Returns:\n",
    "        Un diccionario con los conteos de n-gramas.\n",
    "    \"\"\"\n",
    "    ngram_counts = Counter()\n",
    "    \n",
    "    for sentence in tokenized_sentences:\n",
    "        ngrams = list(nltk.ngrams(sentence, n))\n",
    "        ngram_counts.update(ngrams)\n",
    "    \n",
    "    return ngram_counts\n",
    "\n",
    "\n",
    "def calculate_ngram_probabilities(tokenized_sentences, n):\n",
    "    \"\"\"\n",
    "    Calcula las probabilidades de n-gramas con suavizado de Laplace.\n",
    "    \n",
    "    Args:\n",
    "        tokenized_sentences: Lista de listas de tokens.\n",
    "        n: Tamaño del n-grama.\n",
    "        \n",
    "    Returns:\n",
    "        Diccionario con las probabilidades de los n-gramas.\n",
    "    \"\"\"\n",
    "    # Cuenta los n-gramas y de ser necesario los (n-1)-gramas, para bigramas y trigramas.\n",
    "    ngram_counts = build_ngram_counts(tokenized_sentences, n)\n",
    "    n_minus_1_gram_counts = build_ngram_counts(tokenized_sentences, n-1) if n > 1 else None\n",
    "\n",
    "    # Tamaño del vocabulario\n",
    "    vocabulary = set(token for sentence in tokenized_sentences for token in sentence)\n",
    "    vocab_size = len(vocabulary)\n",
    "\n",
    "    # Diccionario que representará nuestro modelo\n",
    "    ngram_probabilities = {}\n",
    "\n",
    "    for ngram, count in tqdm(ngram_counts.items(), desc=f\"Calculando {n}-gramas\"):\n",
    "        if n == 1:\n",
    "            # Para unigramas el conteo es sencillo\n",
    "            total_count = sum(ngram_counts.values())\n",
    "            ngram_probabilities[ngram] = (count + 1) / (total_count + vocab_size)\n",
    "        else:\n",
    "            # Para bigramas y trigramas hay que tener en cuenta el contexto\n",
    "            priori = ngram[:-1]\n",
    "            priori_count = n_minus_1_gram_counts[priori]\n",
    "            ngram_probabilities[ngram] = (count + 1) / (priori_count + vocab_size)\n",
    "    \n",
    "    return ngram_probabilities\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:33:27.151930Z",
     "start_time": "2024-09-08T17:32:56.238983Z"
    }
   },
   "source": [
    "tokenized_sentences = read_and_tokenize('20N_training.txt')\n",
    "\n",
    "unigram_probs = calculate_ngram_probabilities(tokenized_sentences, 1)\n",
    "bigram_probs = calculate_ngram_probabilities(tokenized_sentences, 2)\n",
    "trigram_probs = calculate_ngram_probabilities(tokenized_sentences, 3)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando 1-gramas: 100%|██████████| 59932/59932 [00:20<00:00, 2908.84it/s]\n",
      "Calculando 2-gramas: 100%|██████████| 876759/876759 [00:00<00:00, 1836080.48it/s]\n",
      "Calculando 3-gramas: 100%|██████████| 1987416/1987416 [00:01<00:00, 1431038.08it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:33:50.929349Z",
     "start_time": "2024-09-08T17:33:50.695516Z"
    }
   },
   "source": [
    "print(\"Unigrams:\")\n",
    "for unigram, prob in list(unigram_probs.items())[:5]:\n",
    "    print(f\"{unigram}: {prob}\")\n",
    "\n",
    "print(\"\\nBigrams:\")\n",
    "for bigram, prob in list(bigram_probs.items())[:5]:\n",
    "    print(f\"{bigram}: {prob}\")\n",
    "\n",
    "print(\"\\nTrigrams:\")\n",
    "for trigram, prob in list(trigram_probs.items())[:5]:\n",
    "    print(f\"{trigram}: {prob}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams:\n",
      "('<s>',): 0.04503576332656161\n",
      "('he',): 0.0022986411800116147\n",
      "('was',): 0.004061853057339074\n",
      "('one',): 0.0026006903238792738\n",
      "('of',): 0.019572312570837015\n",
      "\n",
      "Bigrams:\n",
      "('<s>', 'he'): 0.007249381928383444\n",
      "('he', 'was'): 0.016807325754966126\n",
      "('was', 'one'): 0.001646271907082858\n",
      "('one', 'of'): 0.02739880482579772\n",
      "('of', 'the'): 0.1371147802593912\n",
      "\n",
      "Trigrams:\n",
      "('<s>', 'he', 'was'): 0.0032389188488882413\n",
      "('he', 'was', 'one'): 0.0002454911459526693\n",
      "('was', 'one', 'of'): 0.001365346831396317\n",
      "('one', 'of', 'the'): 0.01679191919191919\n",
      "('of', 'the', 'best'): 0.0007167917908477006\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:04:09.082505Z",
     "start_time": "2024-09-09T01:04:09.078908Z"
    }
   },
   "source": [
    "def save_ngram_model(ngram_probabilities, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(ngram_probabilities, file)\n",
    "\n",
    "def load_ngram_model(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        ngram_probabilities = pickle.load(file)\n",
    "    return ngram_probabilities"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefiero usar el formato `pickle` para guardar cosas en python."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:33:59.348964Z",
     "start_time": "2024-09-08T17:33:58.151002Z"
    }
   },
   "source": [
    "save_ngram_model(unigram_probs, \"20N_unigrams.pkl\")\n",
    "save_ngram_model(bigram_probs, \"20N_bigrams.pkl\")\n",
    "save_ngram_model(trigram_probs, \"20N_trigrams.pkl\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:34:26.624508Z",
     "start_time": "2024-09-08T17:34:26.619648Z"
    }
   },
   "source": "bigram_probs.get((\"</s>\", \"<s>\"), 0) # Esto antes si se permitía, creo que no tiene sentido.",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BAC\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:15:45.838420Z",
     "start_time": "2024-09-09T01:04:13.981587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_sentences_bac = read_and_tokenize('BAC_training.txt')\n",
    "\n",
    "unigram_probs_bac = calculate_ngram_probabilities(tokenized_sentences_bac, 1)\n",
    "bigram_probs_bac = calculate_ngram_probabilities(tokenized_sentences_bac, 2)\n",
    "trigram_probs_bac = calculate_ngram_probabilities(tokenized_sentences_bac, 3)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando 1-gramas: 100%|██████████| 270768/270768 [07:09<00:00, 630.21it/s]\n",
      "Calculando 2-gramas: 100%|██████████| 8906515/8906515 [00:05<00:00, 1502198.07it/s]\n",
      "Calculando 3-gramas: 100%|██████████| 31440652/31440652 [00:25<00:00, 1248350.24it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:15:49.094601Z",
     "start_time": "2024-09-09T01:15:45.850490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Unigrams:\")\n",
    "for unigram, prob in list(unigram_probs_bac.items())[:5]:\n",
    "    print(f\"{unigram}: {prob}\")\n",
    "\n",
    "print(\"\\nBigrams:\")\n",
    "for bigram, prob in list(bigram_probs_bac.items())[:5]:\n",
    "    print(f\"{bigram}: {prob}\")\n",
    "\n",
    "print(\"\\nTrigrams:\")\n",
    "for trigram, prob in list(trigram_probs_bac.items())[:5]:\n",
    "    print(f\"{trigram}: {prob}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams:\n",
      "('<s>',): 0.0550630506781083\n",
      "('NUM',): 0.01998111338660891\n",
      "('march',): 0.00018862921864169348\n",
      "('time',): 0.0022691336679541425\n",
      "('yrs',): 1.2544857697280485e-05\n",
      "\n",
      "Bigrams:\n",
      "('<s>', 'NUM'): 0.08265888083493486\n",
      "('NUM', 'march'): 0.0066421028673511896\n",
      "('march', 'NUM'): 0.058839948448279424\n",
      "('NUM', 'time'): 0.00032293666232935245\n",
      "('time', 'NUM'): 0.0025313896278440964\n",
      "\n",
      "Trigrams:\n",
      "('<s>', 'NUM', 'march'): 0.019957894957894958\n",
      "('NUM', 'march', 'NUM'): 0.053823095788760246\n",
      "('march', 'NUM', 'time'): 5.9060178848118065e-05\n",
      "('NUM', 'time', 'NUM'): 0.0004456410048652212\n",
      "('time', 'NUM', 'yrs'): 1.837937980620782e-05\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:17:35.509976Z",
     "start_time": "2024-09-09T01:17:16.194364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_ngram_model(unigram_probs_bac, \"BAC_unigrams.pkl\")\n",
    "save_ngram_model(bigram_probs_bac, \"BAC_bigrams.pkl\")\n",
    "save_ngram_model(trigram_probs_bac, \"BAC_trigrams.pkl\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T01:19:02.836077Z",
     "start_time": "2024-09-09T01:19:02.760774Z"
    }
   },
   "cell_type": "code",
   "source": "bigram_probs.get((\"</s>\", \"<s>\"), 0)  # Esto antes si se permitía, creo que no tiene sentido.",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mbigram_probs\u001B[49m\u001B[38;5;241m.\u001B[39mget((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</s>\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<s>\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# Esto antes si se permitía, creo que no tiene sentido.\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'bigram_probs' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando texto"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:34:32.773952Z",
     "start_time": "2024-09-08T17:34:32.761448Z"
    }
   },
   "source": [
    "def generate_text(model, start_sentence, max_length=20, n=1):\n",
    "    \"\"\"\n",
    "    Genera texto usando el modelo n-grama basado en el n-grama de mayor probabilidad.\n",
    "\n",
    "    Args:\n",
    "        model: Diccionario de n-gramas con sus probabilidades.\n",
    "        start_sentence: Frase de inicio como string.\n",
    "        max_length: Longitud máxima de la oración generada.\n",
    "        n: Tamaño del n-grama (ej. 1 para unigramas).\n",
    "\n",
    "    Returns:\n",
    "        string: Oración generada.\n",
    "    \"\"\"\n",
    "    sentence = start_sentence.split()\n",
    "\n",
    "    if n == 1:\n",
    "        # Para unigramas, seleccionamos el token con la mayor probabilidad en cada paso\n",
    "        # En realidad no tiene sentido generar con unigramas\n",
    "        for _ in range(max_length):\n",
    "            next_token = max(model, key=model.get)\n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "            sentence.append(next_token[0])\n",
    "    else:\n",
    "        # Para n-gramas donde n > 1\n",
    "        for _ in range(max_length):\n",
    "            if len(sentence) < n-1:\n",
    "                context = tuple(sentence)  # Usa toda la oración disponible\n",
    "            else:\n",
    "                context = tuple(sentence[-(n-1):])  # Toma los últimos n-1 tokens como contexto\n",
    "            \n",
    "            # Buscar las posibles continuaciones en el modelo\n",
    "            possible_ngrams = [ngram for ngram in model if ngram[:-1] == context]\n",
    "            \n",
    "            if not possible_ngrams:\n",
    "                break\n",
    "            \n",
    "            next_token = max(possible_ngrams, key=lambda ngram: model[ngram])[-1]\n",
    "            \n",
    "            if next_token == '</s>':\n",
    "                break\n",
    "            sentence.append(next_token)\n",
    "    \n",
    "    return ' '.join(sentence)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:34:50.191091Z",
     "start_time": "2024-09-08T17:34:43.498833Z"
    }
   },
   "source": [
    "generate_text(trigram_probs, \"<s> hi\", max_length= 50, n = 3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hi i am not sure if this is a good idea to have a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM a NUM'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:34:59.100319Z",
     "start_time": "2024-09-08T17:34:58.851908Z"
    }
   },
   "source": [
    "generate_text(unigram_probs, \"<s>\", max_length= 50, n = 1)\n",
    "# Obviamente generar con unigramas no tiene sentido."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM NUM'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:35:04.456823Z",
     "start_time": "2024-09-08T17:35:04.453410Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "def calculate_perplexity_log(model, test_sentences, n):\n",
    "    total_log_prob = 0\n",
    "    total_ngrams = 0\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        sentence_log_prob = 0\n",
    "        ngram_count = 0\n",
    "        \n",
    "        n_grams = list(nltk.ngrams(sentence,n))\n",
    "\n",
    "        for ngram in n_grams:            \n",
    "            if ngram in model:\n",
    "                prob = model[ngram]\n",
    "            else:\n",
    "                prob = 1e-10\n",
    "            \n",
    "            sentence_log_prob += math.log(prob)\n",
    "            ngram_count += 1\n",
    "        \n",
    "        total_log_prob += sentence_log_prob\n",
    "        total_ngrams += ngram_count\n",
    "    \n",
    "    avg_log_prob = total_log_prob / total_ngrams\n",
    "    perplexity = math.exp(-avg_log_prob)\n",
    "    \n",
    "    return perplexity"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:35:08.303790Z",
     "start_time": "2024-09-08T17:35:08.079727Z"
    }
   },
   "source": [
    "test_sentences = read_and_tokenize(\"20N_testing.txt\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:35:12.470065Z",
     "start_time": "2024-09-08T17:35:11.887421Z"
    }
   },
   "source": [
    "perplexity = calculate_perplexity_log(trigram_probs, test_sentences, n=3)\n",
    "print(f'Perplejidad del modelo de trigramas: {perplexity}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplejidad del modelo de trigramas: 1536973.141016124\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:35:13.138494Z",
     "start_time": "2024-09-08T17:35:12.547579Z"
    }
   },
   "source": [
    "perplexity = calculate_perplexity_log(bigram_probs, test_sentences, n=2) \n",
    "print(f'Perplejidad del modelo de bigramas: {perplexity}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplejidad del modelo de bigramas: 11566.077818175523\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:35:20.517686Z",
     "start_time": "2024-09-08T17:35:20.120018Z"
    }
   },
   "source": [
    "perplexity = calculate_perplexity_log(unigram_probs, test_sentences, n=1)\n",
    "print(f'Perplejidad del modelo de unigramas: {perplexity}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplejidad del modelo de unigramas: 960.3839554547949\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
